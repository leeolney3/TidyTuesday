---
title: "Tidy Tuesday 2021 Week 40 v2"
date: "2021/09/28"
output: html_notebook
---

TidyTuesday week 40: NBER papers, data from the National Bureau of Economic Research [NBER](https://www2.nber.org/RePEc/nbr/nberwo/) by way of the [nberwp package by Ben Davies](https://github.com/bldavies/nberwp).


```{r}
library(tidyverse)
library(glue)
library(gt)
library(gtExtras)
```

```{r}
papers <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2021/2021-09-28/papers.csv')
authors <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2021/2021-09-28/authors.csv')
programs <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2021/2021-09-28/programs.csv')
paper_authors <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2021/2021-09-28/paper_authors.csv')
paper_programs <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2021/2021-09-28/paper_programs.csv')
```

```{r}
joined_df <- left_join(papers, paper_authors) %>% 
  left_join(authors) %>% 
  left_join(paper_programs) %>% 
  left_join(programs)%>% 
  mutate(
    catalogue_group = str_sub(paper, 1, 1),
    catalogue_group = case_when(
      catalogue_group == "h" ~ "Historical",
      catalogue_group == "t" ~ "Technical",
      catalogue_group == "w" ~ "General"
    ),
    .after = paper
  ) 
```

### Working paper count by program and decade
* shared on [Twitter](https://twitter.com/leeolney3/status/1442671857015087106)

```{r}
wp = joined_df %>% group_by(program, program_desc, year) %>%
  summarise(n=n_distinct(paper)) %>%
  arrange(year) %>%
  mutate(decade=case_when(between(year,1980,1989)~"1980s",
                          between(year,1990,1999)~"1990s",
                          between(year,2000,2009)~"2000s",
                          between(year,2010,2019)~"2010s"
                          )) %>%
  drop_na() 

wp2 = wp %>% mutate(program=glue::glue("{program_desc} ({program})")) %>%
  group_by(program) %>% mutate(total=sum(n)) %>%
  arrange(year, program) %>%
  mutate(spark=list(n)) %>%
  select(program, spark, total) %>%
  distinct()

wp3 = wp %>% mutate(program=glue::glue("{program_desc} ({program})")) %>%
  group_by(program, decade) %>% tally(n) %>% 
  ungroup() %>%
  pivot_wider(names_from = decade, values_from=n) %>%
  mutate_if(is.numeric, list(~replace_na(., 0)))
```


```{r}
wp3 %>% inner_join(wp2, by="program") %>%
  select(Program=program, Total=total, "1980s","1990s","2000s","2010s",Trend=spark) %>%
  arrange(desc(Total)) %>%
  gt() %>%
  gt_theme_espn() %>%
  cols_align(Program, align="left") %>%
  gt_plt_dot(Total, Program,palette = "rcartocolor::ag_GrnYl", max_value=5246) %>%
  gtExtras::gt_sparkline(Trend) %>%
  tab_options(table.font.size = 12.5,
              heading.subtitle.font.size = 14) %>%
  gt_color_box(`1980s`, domain=2:786) %>%
  gt_color_box(`1990s`, domain=2:797) %>%
  gt_color_box(`2000s`, domain=132:1647) %>%
  gt_color_box(`2010s`, domain=200:2424) %>%
  tab_header(title="Economic Papers", subtitle="Working papers count by program and decade") %>%
  tab_source_note(source_note="TidyTuesday Week 40 | Data source: National Bureau of Economic Research (NBER) by way of the nberwp package by Ben Davies") 
```

ALT text: The table showing the count of NBER papers, by program and decade, from 1980 to 2019, where Labor studies program have the highest total working paper (n=5246) in the time period and Technical Working papers have the lowest total (n=335). The table includes a spark line showing the yearly counts of working paper, where all programs have higher counts of working papers in recent years, except for International Trade and Investment program. 

### Predict program category from title and year
* Code reference: youtube.com/watch?v=fooYB4n-ZfU

```{r}
papers_joined <-
  paper_programs %>%
  left_join(programs) %>%
  left_join(papers) %>%
  filter(!is.na(program_category)) %>%
  distinct(paper, program_category, year, title)
```

```{r}
library(Hmisc)
Hmisc::describe(papers_joined$program_category)
```

```{r}
library(ggthemes)
theme_set(theme_gdocs(base_size = 9))
theme_update(plot.margin = unit(c(1.1,.7,1,.7), "cm"),
             plot.background = element_rect(color=NA),
             strip.text.x=element_text(size = 10, color="black", margin=margin(b=10)))
```

```{r}
library(tidytext)
library(tidylo)
```

```{r}
title_log_odds <-
  papers_joined %>%
  unnest_tokens(word, title) %>%
  filter(!is.na(program_category)) %>%
  count(program_category, word, sort = TRUE) %>%
  bind_log_odds(program_category, word, n)

title_log_odds %>%
  group_by(program_category) %>%
  slice_max(log_odds_weighted, n = 10) %>%
  ungroup() %>%
  ggplot(aes(log_odds_weighted,
    fct_reorder(word, log_odds_weighted),
    fill = program_category
  )) +
  geom_col(show.legend = FALSE, width=0.5, alpha=.8) +
  facet_wrap(vars(program_category), scales = "free_y") +
  labs(x = "Log odds (weighted)", y = NULL) +
  theme(panel.grid.major.y=element_blank()) +
  scale_fill_fivethirtyeight()
```

```{r}
library(tidymodels)
library(themis)
library(textrecipes)
```

```{r}
set.seed(123)
nber_split <- initial_split(papers_joined, strata = program_category)
nber_train <- training(nber_split)
nber_test <- testing(nber_split)

set.seed(234)
nber_folds <- vfold_cv(nber_train, strata = program_category)
nber_folds
```

```{r}
# feature engineering setup
nber_rec <-
  recipe(program_category ~ year + title, data = nber_train) %>%
  step_tokenize(title) %>%
  step_tokenfilter(title, max_tokens = 200) %>%
  step_tfidf(title) %>%
  step_downsample(program_category)

nber_rec
```

```{r}
# model specification for a lasso model
multi_spec <-
  multinom_reg(penalty = tune(), mixture = 1) %>%
  set_mode("classification") %>%
  set_engine("glmnet")

multi_spec
```

```{r}
# preprocessing and model together in a workflow()
nber_wf <- workflow(nber_rec, multi_spec)
nber_wf
```


```{r}
# tune over a grid of possible penalty parameters
nber_grid <- grid_regular(penalty(range = c(-5, 0)), levels = 20)

doParallel::registerDoParallel()
set.seed(2021)
nber_rs <-
  tune_grid(
    nber_wf,
    nber_folds,
    grid = nber_grid
  )

nber_rs
```

```{r, message=F, warning=F}
autoplot(nber_rs) 

show_best(nber_rs)
```

```{r}
# choose and evaluate final model
final_penalty <-
  nber_rs %>%
  select_by_one_std_err(metric = "roc_auc", desc(penalty))

final_penalty
```

```{r}
final_rs <-
  nber_wf %>%
  finalize_workflow(final_penalty) %>%
  last_fit(nber_split)

final_rs
```

```{r}
collect_metrics(final_rs)
```
```{r}
collect_predictions(final_rs) %>%
  conf_mat(program_category, .pred_class) %>%
  autoplot()
```

```{r}
collect_predictions(final_rs) %>%
  roc_curve(truth = program_category, .pred_Finance:.pred_Micro) %>%
  ggplot(aes(1 - specificity, sensitivity, color = .level)) +
  geom_abline(slope = 1, color = "gray50", lty = 2, alpha = 0.8) +
  geom_path(size = 1, alpha = 0.7) +
  labs(color = NULL) +
  coord_fixed() +
  scale_color_fivethirtyeight()
```

```{r}
# extract (and save)
final_fitted <- extract_workflow(final_rs)
## readr::write_rds()
```

